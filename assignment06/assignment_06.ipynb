{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYhpo2gw0QS3"
      },
      "source": [
        "# Multi-class classification using pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny9dv0lK0QS4"
      },
      "source": [
        "## import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AmfNz9Yv0QS4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.transforms.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa8MnyrY0QS5"
      },
      "source": [
        "## load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tOHD0ngw0QS5"
      },
      "outputs": [],
      "source": [
        "directory_data  = './sample_data'\n",
        "filename_data   = 'assignment_06_data.npz'\n",
        "data            = np.load(os.path.join(directory_data, filename_data))\n",
        "\n",
        "x_train = data['x_train']\n",
        "y_train = data['y_train']\n",
        "\n",
        "x_test  = data['x_test']\n",
        "y_test  = data['y_test']\n",
        "\n",
        "num_data_train  = x_train.shape[0]\n",
        "num_data_test   = x_test.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ziy1L3hH0QS5",
        "outputId": "be330ef6-2075-4422-86d2-a02c7069fa39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************************************\n",
            "size of x_train : (20000, 32, 32)\n",
            "size of y_train : (20000,)\n",
            "*************************************************\n",
            "size of x_test : (8000, 32, 32)\n",
            "size of y_test : (8000,)\n",
            "*************************************************\n",
            "number of training image : 20000\n",
            "height of training image : 32\n",
            "width of training image : 32\n",
            "*************************************************\n",
            "number of testing image : 8000\n",
            "height of testing image : 32\n",
            "width of testing image : 32\n",
            "*************************************************\n"
          ]
        }
      ],
      "source": [
        "print('*************************************************')\n",
        "print('size of x_train :', x_train.shape)\n",
        "print('size of y_train :', y_train.shape)\n",
        "print('*************************************************')\n",
        "print('size of x_test :', x_test.shape)\n",
        "print('size of y_test :', y_test.shape)\n",
        "print('*************************************************')\n",
        "print('number of training image :', x_train.shape[0])\n",
        "print('height of training image :', x_train.shape[1])\n",
        "print('width of training image :', x_train.shape[2])\n",
        "print('*************************************************')\n",
        "print('number of testing image :', x_test.shape[0])\n",
        "print('height of testing image :', x_test.shape[1])\n",
        "print('width of testing image :', x_test.shape[2])\n",
        "print('*************************************************')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U29V2iNL0QS6"
      },
      "source": [
        "## number of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jwzDSOGS0QS6",
        "outputId": "1c6dd912-b39f-4d62-d823-866977ebea4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************************************\n",
            "number of classes : 10\n",
            "*************************************************\n"
          ]
        }
      ],
      "source": [
        "print('*************************************************')\n",
        "print('number of classes :', len(set(y_train)))\n",
        "print('*************************************************')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm8RyxaK0QS7"
      },
      "source": [
        "## custom data loader for the PyTorch framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RttVv2-c0QS7"
      },
      "outputs": [],
      "source": [
        "class dataset(Dataset):\n",
        "    \n",
        "    def __init__(self, image, label):\n",
        "        \n",
        "        self.image  = image\n",
        "        self.label  = label.astype(int)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        image   = self.image[index, :, :]\n",
        "        label   = self.label[index, ]\n",
        "\n",
        "        image   = torch.FloatTensor(image).unsqueeze(dim=0)\n",
        "        label   = torch.LongTensor([label])\n",
        "\n",
        "        return image, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return self.image.shape[0]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        images  = list()\n",
        "        labels  = list()\n",
        "\n",
        "        for b in batch:\n",
        "            images.append(b[0])\n",
        "            labels.append(b[1])\n",
        "\n",
        "        images  = torch.stack(images, dim=0)\n",
        "        labels  = torch.stack(labels, dim=0).squeeze()\n",
        "\n",
        "        return images, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKcC5IDv0QS7"
      },
      "source": [
        "## setting device (cpu or gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eo93A6K40QS7"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "J8Xl9XN50QS8",
        "outputId": "7581b8c8-fa01-47d9-def4-7c120dca7c23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54ZG-1Jt0QS8"
      },
      "source": [
        "## construct datasets and dataloaders for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8_JiR2q90QS8",
        "outputId": "74ac77c1-cdd3-4966-e21c-0b43a47dd033",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x,y train type:  <class 'numpy.ndarray'>\n",
            "dataset() type:  <class '__main__.dataset'>\n",
            "dataloader_train type :  <class 'torch.utils.data.dataloader.DataLoader'>\n"
          ]
        }
      ],
      "source": [
        "# ================================================== \n",
        "# determine the value of the following parameter\n",
        "#\n",
        "size_minibatch      = 100\n",
        "#\n",
        "# ================================================== \n",
        "print(\"x,y train type: \", type(x_train))\n",
        "dataset_train       = dataset(x_train, y_train)\n",
        "dataset_test        = dataset(x_test, y_test)\n",
        "print(\"dataset() type: \", type(dataset_train))\n",
        "\n",
        "dataloader_train    = torch.utils.data.DataLoader(dataset_train, batch_size=size_minibatch, shuffle=True, drop_last=True, collate_fn=dataset_train.collate_fn)\n",
        "dataloader_test     = torch.utils.data.DataLoader(dataset_test, batch_size=size_minibatch, shuffle=True, drop_last=True, collate_fn=dataset_test.collate_fn)\n",
        "print(\"dataloader_train type : \", type(dataloader_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRnV4HMZ0QS8"
      },
      "source": [
        "## shape of the data when using the data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fPz9v3cC0QS8"
      },
      "outputs": [],
      "source": [
        "image, label    = next(iter(dataloader_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "feDV47CW0QS8",
        "outputId": "39cb4f6c-5226-405b-81d9-9c0aed6cb564",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************************************************************\n",
            "size of mini-batch of the image: torch.Size([100, 1, 32, 32])\n",
            "************************************************************\n",
            "size of mini-batch of the label: torch.Size([100])\n",
            "************************************************************\n"
          ]
        }
      ],
      "source": [
        "print('************************************************************')\n",
        "print('size of mini-batch of the image:', image.shape)\n",
        "print('************************************************************')\n",
        "print('size of mini-batch of the label:', label.shape)\n",
        "print('************************************************************')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5xmjVMS0QS9"
      },
      "source": [
        "## construct a neural network "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-ulkyxR80QS9"
      },
      "outputs": [],
      "source": [
        "# ================================================== \n",
        "# define the neural network architecture\n",
        "#\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        self.feature    = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=2, out_channels=4, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(32, 16, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 10, bias=True),\n",
        "        )\n",
        "\n",
        "        self.network    = nn.Sequential(\n",
        "            self.feature,\n",
        "            nn.Flatten(),\n",
        "            self.classifier,\n",
        "        )\n",
        "\n",
        "        self.initialize()\n",
        "\n",
        "\n",
        "    def initialize(self):\n",
        "\n",
        "        for m in self.network.modules():\n",
        "\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "\n",
        "                #nn.init.constant_(m.weight, 0.01)\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                nn.init.constant_(m.bias, 1)\n",
        "\n",
        "            elif isinstance(m, nn.Linear):\n",
        "    \n",
        "                #nn.init.constant_(m.weight, 0.01)\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                nn.init.constant_(m.bias, 1)\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        output = self.network(input)\n",
        "\n",
        "        return output\n",
        "#\n",
        "# ================================================== "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csfr = Classifier()\n",
        "print(type(csfr))\n",
        "otp = csfr.forward(image)\n",
        "print(type(otp))\n",
        "print(otp.shape)\n",
        "# print(otp)"
      ],
      "metadata": {
        "id": "jJWg5-j_HQmv",
        "outputId": "b6a1d877-b48b-4981-891e-1b0e4ca89025",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class '__main__.Classifier'>\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([100, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqepuNjx0QS9"
      },
      "source": [
        "## build network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "twi4-yCs0QS9"
      },
      "outputs": [],
      "source": [
        "# ================================================== \n",
        "# determine the value of the following parameter\n",
        "#\n",
        "learning_rate   = 0.05\n",
        "weight_decay    = 0.01\n",
        "#\n",
        "# ================================================== \n",
        "\n",
        "classifier      = Classifier().to(device)\n",
        "optimizer       = torch.optim.SGD(classifier.parameters(), lr=learning_rate, weight_decay=weight_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0eNEe8Qf0QS9",
        "outputId": "5d53f847-2fd8-41c5-e9ac-ce6b1fc34b0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier(\n",
            "  (feature): Sequential(\n",
            "    (0): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): ReLU()\n",
            "    (3): Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): ReLU()\n",
            "    (6): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): ReLU()\n",
            "    (9): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (11): ReLU()\n",
            "    (12): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): ReLU()\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=16, out_features=10, bias=True)\n",
            "  )\n",
            "  (network): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(1, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (2): ReLU()\n",
            "      (3): Conv2d(2, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): ReLU()\n",
            "      (6): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (8): ReLU()\n",
            "      (9): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (11): ReLU()\n",
            "      (12): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (14): ReLU()\n",
            "    )\n",
            "    (1): Flatten(start_dim=1, end_dim=-1)\n",
            "    (2): Sequential(\n",
            "      (0): Linear(in_features=32, out_features=16, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=16, out_features=10, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpa3cJjw0QS-"
      },
      "source": [
        "## compute the prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aG9N4p9Q0QS-"
      },
      "outputs": [],
      "source": [
        "def compute_prediction(model, input):\n",
        "\n",
        "# ================================================== \n",
        "# fill up the blank\n",
        "# \n",
        "    prediction = model.forward(input)\n",
        "    \n",
        "#\n",
        "# ================================================== \n",
        "\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0Uz-8D10QS-"
      },
      "source": [
        "## compute the loss\n",
        "- use `CrossEntropyLoss`\n",
        "- compute loss and its value (`loss.item()`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WMkPBPQ0QS-"
      },
      "outputs": [],
      "source": [
        "def compute_loss(prediction, label):\n",
        "\n",
        "# ================================================== \n",
        "# fill up the blank\n",
        "#    \n",
        " \n",
        "    loss        = \n",
        "\n",
        "#\n",
        "# ================================================== \n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq4TPsye0QS-"
      },
      "source": [
        "## compute the loss value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EZ8dC-J0QS-"
      },
      "outputs": [],
      "source": [
        "def compute_loss_value(loss):\n",
        "    \n",
        "    loss_value = loss.item()\n",
        "    \n",
        "    return loss_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF9i0mH-0QS_"
      },
      "source": [
        "## compute the accuracy\n",
        "- accuracy in percentile : 0 - 100 (%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TefUztWa0QS_"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(prediction, label):\n",
        "\n",
        "# ================================================== \n",
        "# fill up the blank\n",
        "#         \n",
        "\n",
        "    accuracy = \n",
        "\n",
        "#\n",
        "# ================================================== \n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40gCqpHV0QS_"
      },
      "source": [
        "## variables for the learning curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chRbMIYA0QS_"
      },
      "outputs": [],
      "source": [
        "# ================================================== \n",
        "# determine the value of the following parameter\n",
        "#\n",
        "number_epoch        = 10\n",
        "#\n",
        "# ================================================== \n",
        "\n",
        "loss_train_mean     = np.zeros(number_epoch)\n",
        "loss_train_std      = np.zeros(number_epoch)\n",
        "accuracy_train_mean = np.zeros(number_epoch)\n",
        "accuracy_train_std  = np.zeros(number_epoch)\n",
        "\n",
        "loss_test_mean      = np.zeros(number_epoch)\n",
        "loss_test_std       = np.zeros(number_epoch)\n",
        "accuracy_test_mean  = np.zeros(number_epoch)\n",
        "accuracy_test_std   = np.zeros(number_epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nun9uPt10QS_"
      },
      "source": [
        "## train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZ5kV5pe0QS_"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# \n",
        "# iterations for epochs\n",
        "#\n",
        "# ================================================================================\n",
        "for i in tqdm(range(number_epoch)):\n",
        "    \n",
        "    # ================================================================================\n",
        "    # \n",
        "    # training\n",
        "    #\n",
        "    # ================================================================================\n",
        "    loss_train_epoch        = []\n",
        "    accuracy_train_epoch    = []\n",
        "\n",
        "    classifier.train()\n",
        "\n",
        "    for index_batch, (image_train, label_train) in enumerate(dataloader_train):\n",
        "\n",
        "        image_train = image_train.to(device)\n",
        "        label_train = label_train.to(device)\n",
        "\n",
        "# ================================================== \n",
        "# fill up the blank\n",
        "#       \n",
        "  \n",
        "        loss_train              = \n",
        "        loss_value_train        =\n",
        "        accuracy_train          = \n",
        "        \n",
        "#\n",
        "# ================================================== \n",
        "\n",
        "        loss_train_epoch.append(loss_value_train)\n",
        "        accuracy_train_epoch.append(accuracy_train)\n",
        "\n",
        "# ================================================== \n",
        "# fill up the blank (update moodel parameters using a mini-batch)\n",
        "#       \n",
        "\n",
        "\n",
        "#\n",
        "# ==================================================  \n",
        "\n",
        "\n",
        "    loss_train_mean[i]      = np.mean(loss_train_epoch)\n",
        "    loss_train_std[i]       = np.std(loss_train_epoch)\n",
        "\n",
        "    accuracy_train_mean[i]  = np.mean(accuracy_train_epoch)\n",
        "    accuracy_train_std[i]   = np.std(accuracy_train_epoch)\n",
        "\n",
        "    # ================================================================================\n",
        "    # \n",
        "    # testing\n",
        "    #\n",
        "    # ================================================================================\n",
        "    loss_test_epoch        = []\n",
        "    accuracy_test_epoch    = []\n",
        "\n",
        "    classifier.eval()\n",
        "\n",
        "    for index_batch, (image_test, label_test) in enumerate(dataloader_test):\n",
        "\n",
        "        image_test = image_test.to(device)\n",
        "        label_test = label_test.to(device)\n",
        "\n",
        "# ================================================== \n",
        "# fill up the blank\n",
        "#         \n",
        " \n",
        "        loss_test       = \n",
        "        loss_value_test = \n",
        "        accuracy_test   = \n",
        "        \n",
        "#\n",
        "# ================================================== \n",
        " \n",
        "        loss_test_epoch.append(loss_value_test)\n",
        "        accuracy_test_epoch.append(accuracy_test)\n",
        "\n",
        "    loss_test_mean[i]      = np.mean(loss_test_epoch)\n",
        "    loss_test_std[i]       = np.std(loss_test_epoch)\n",
        "\n",
        "    accuracy_test_mean[i]  = np.mean(accuracy_test_epoch)\n",
        "    accuracy_test_std[i]   = np.std(accuracy_test_epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laGW-AFO0QTA"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgDs44EU0QTA"
      },
      "source": [
        "## functions for presenting the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wf-raoTZ0QTA"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRrMt9sb0QTA"
      },
      "outputs": [],
      "source": [
        "def function_result_01():\n",
        "\n",
        "    title           = 'loss (training)'\n",
        "    label_axis_x    = 'epoch' \n",
        "    label_axis_y    = 'loss'\n",
        "    color_mean      = 'red'\n",
        "    color_std       = 'blue'\n",
        "    alpha           = 0.3\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.title(title)\n",
        "\n",
        "    plt.plot(range(len(loss_train_mean)), loss_train_mean, '-', color = color_mean)\n",
        "    plt.fill_between(range(len(loss_train_mean)), loss_train_mean - loss_train_std, loss_train_mean + loss_train_std, facecolor = color_std, alpha = alpha) \n",
        "    \n",
        "    plt.xlabel(label_axis_x)\n",
        "    plt.ylabel(label_axis_y)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPe3UYmT0QTA"
      },
      "outputs": [],
      "source": [
        "def function_result_02():\n",
        "\n",
        "    title           = 'loss (testing)'\n",
        "    label_axis_x    = 'epoch' \n",
        "    label_axis_y    = 'loss'\n",
        "    color_mean      = 'red'\n",
        "    color_std       = 'blue'\n",
        "    alpha           = 0.3\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.title(title)\n",
        "\n",
        "    plt.plot(range(len(loss_test_mean)), loss_test_mean, '-', color = color_mean)\n",
        "    plt.fill_between(range(len(loss_test_mean)), loss_test_mean - loss_test_std, loss_test_mean + loss_test_std, facecolor = color_std, alpha = alpha) \n",
        "    \n",
        "    plt.xlabel(label_axis_x)\n",
        "    plt.ylabel(label_axis_y)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iyG8Qr_0QTA"
      },
      "outputs": [],
      "source": [
        "def function_result_03():\n",
        "\n",
        "    title           = 'accuracy (training)'\n",
        "    label_axis_x    = 'epoch' \n",
        "    label_axis_y    = 'accuracy'\n",
        "    color_mean      = 'red'\n",
        "    color_std       = 'blue'\n",
        "    alpha           = 0.3\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.title(title)\n",
        "\n",
        "    plt.plot(range(len(accuracy_train_mean)), accuracy_train_mean, '-', color = color_mean)\n",
        "    plt.fill_between(range(len(accuracy_train_mean)), accuracy_train_mean - accuracy_train_std, accuracy_train_mean + accuracy_train_std, facecolor = color_std, alpha = alpha) \n",
        "    \n",
        "    plt.xlabel(label_axis_x)\n",
        "    plt.ylabel(label_axis_y)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEm4U52s0QTB"
      },
      "outputs": [],
      "source": [
        "def function_result_04():\n",
        "\n",
        "    title           = 'accuracy (testing)'\n",
        "    label_axis_x    = 'epoch' \n",
        "    label_axis_y    = 'accuracy'\n",
        "    color_mean      = 'red'\n",
        "    color_std       = 'blue'\n",
        "    alpha           = 0.3\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.title(title)\n",
        "\n",
        "    plt.plot(range(len(accuracy_test_mean)), accuracy_test_mean, '-', color = color_mean)\n",
        "    plt.fill_between(range(len(accuracy_test_mean)), accuracy_test_mean - accuracy_test_std, accuracy_test_mean + accuracy_test_std, facecolor = color_std, alpha = alpha) \n",
        "    \n",
        "    plt.xlabel(label_axis_x)\n",
        "    plt.ylabel(label_axis_y)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XLkV1uk0QTB"
      },
      "outputs": [],
      "source": [
        "def function_result_05():\n",
        "\n",
        "    print('final training accuracy = %9.8f' % (accuracy_train_mean[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQS34BbE0QTB"
      },
      "outputs": [],
      "source": [
        "def function_result_06():\n",
        "\n",
        "    print('final testing accuracy = %9.8f' % (accuracy_test_mean[-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU06FnZN0QTB"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFnrVStN0QTB"
      },
      "source": [
        "## results "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAmX7bfe0QTB"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ym_NzP5E0QTB"
      },
      "outputs": [],
      "source": [
        "number_result = 6 \n",
        "\n",
        "for i in range(number_result):\n",
        "\n",
        "    title           = '# RESULT # {:02d}'.format(i+1) \n",
        "    name_function   = 'function_result_{:02d}()'.format(i+1)\n",
        "\n",
        "    print('') \n",
        "    print('################################################################################')\n",
        "    print('#') \n",
        "    print(title)\n",
        "    print('#') \n",
        "    print('################################################################################')\n",
        "    print('') \n",
        "\n",
        "    eval(name_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7uohDjZ0QTC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.6 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "metadata": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "vscode": {
      "interpreter": {
        "hash": "936d8260778fd5e616cf4743245910e0749a09bc88b1fefa5a1bd6bde9340953"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}